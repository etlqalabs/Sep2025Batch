{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db20567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Pyspark Day 3\").getOrCreate()\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c253e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "| 10| Amber|  1000|    10|2018-05-14|\n",
      "|  2|  Amar|  1000|    10|2017-03-22|\n",
      "|  4|Thomas|  1000|    10|2019-08-18|\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "|  6| Smith|  1000|    10|2016-12-01|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 21| Sneha|  2700|    10|2022-12-14|\n",
      "| 24| Vinod|  1800|    10|2016-07-30|\n",
      "| 26| Harsh|  1600|    10|2021-09-25|\n",
      "| 28| Mohan|  1300|    10|2015-04-17|\n",
      "| 30|Suresh|  1100|    10|2018-09-09|\n",
      "| 32|  Ajay|  2100|    10|2020-06-26|\n",
      "| 35| Seema|  3000|    10|2021-10-15|\n",
      "| 38|  Alok|  2700|    10|2019-03-02|\n",
      "| 42| Tarun|  2200|    10|2021-01-09|\n",
      "| 44| Ashok|  1900|    10|2016-06-08|\n",
      "+---+------+------+------+----------+\n",
      "\n",
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "| 10| Amber|  1000|    10|2018-05-14|\n",
      "|  2|  Amar|  1000|    10|2017-03-22|\n",
      "|  8| Sagar|  1000|    20|2020-11-30|\n",
      "|  4|Thomas|  1000|    10|2019-08-18|\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "|  6| Smith|  1000|    10|2016-12-01|\n",
      "|  7|Robert|  3000|    20|2023-06-25|\n",
      "|  3|  Nick|  1000|    30|2015-09-15|\n",
      "|  9| Naman|  4000|    30|2020-01-20|\n",
      "|  1| Vikas|  1000|    30|2017-10-03|\n",
      "| 11|Dennis| 41000|    30|2024-01-05|\n",
      "| 12| Karan|  2200|    20|2018-06-16|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 14|  Amit|  2000|    30|2022-04-09|\n",
      "| 15|  Neha|  1700|    20|2021-07-22|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 17| Divya|  3000|    30|2015-11-11|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 19|Monica|  2500|    20|2023-08-07|\n",
      "| 20|  John|  2300|    30|2018-10-29|\n",
      "+---+------+------+------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Filtering and condition (Where)\n",
    "# filter the data for depnto = 10 \n",
    "df = spark.read.csv(\"emp.csv\",header=True)\n",
    "df_filtered = df.filter(df.deptno == 10)\n",
    "df_filtered.show()\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e469e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 21| Sneha|  2700|    10|2022-12-14|\n",
      "| 24| Vinod|  1800|    10|2016-07-30|\n",
      "| 26| Harsh|  1600|    10|2021-09-25|\n",
      "| 28| Mohan|  1300|    10|2015-04-17|\n",
      "| 30|Suresh|  1100|    10|2018-09-09|\n",
      "| 32|  Ajay|  2100|    10|2020-06-26|\n",
      "| 35| Seema|  3000|    10|2021-10-15|\n",
      "| 38|  Alok|  2700|    10|2019-03-02|\n",
      "| 42| Tarun|  2200|    10|2021-01-09|\n",
      "| 44| Ashok|  1900|    10|2016-06-08|\n",
      "+---+------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering and condition (Where)\n",
    "# filter the data for depnto = 10 and salary > 1000\n",
    "df = spark.read.csv(\"emp.csv\",header=True)\n",
    "df_filtered = df.filter((df.deptno == 10) & (df.salary > 1000))\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ea88d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "| 10| Amber|  1000|    10|2018-05-14|\n",
      "|  2|  Amar|  1000|    10|2017-03-22|\n",
      "|  8| Sagar|  1000|    20|2020-11-30|\n",
      "|  4|Thomas|  1000|    10|2019-08-18|\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "|  6| Smith|  1000|    10|2016-12-01|\n",
      "|  7|Robert|  3000|    20|2023-06-25|\n",
      "| 12| Karan|  2200|    20|2018-06-16|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 15|  Neha|  1700|    20|2021-07-22|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 19|Monica|  2500|    20|2023-08-07|\n",
      "| 21| Sneha|  2700|    10|2022-12-14|\n",
      "| 22| David|  1000|    20|2017-02-17|\n",
      "| 24| Vinod|  1800|    10|2016-07-30|\n",
      "| 25| Meena|  2000|    20|2020-03-13|\n",
      "| 26| Harsh|  1600|    10|2021-09-25|\n",
      "| 28| Mohan|  1300|    10|2015-04-17|\n",
      "| 29| Priya|  1200|    20|2023-02-11|\n",
      "+---+------+------+------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# filter the data for depnto = 10 and depnto = 20\n",
    "df = spark.read.csv(\"emp.csv\",header=True)\n",
    "df_filtered = df.filter((df.deptno == 10) | (df.deptno == 20))\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e9ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "| 10| Amber|  1000|    10|2018-05-14|\n",
      "|  2|  Amar|  1000|    10|2017-03-22|\n",
      "|  8| Sagar|  1000|    20|2020-11-30|\n",
      "|  4|Thomas|  1000|    10|2019-08-18|\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "|  6| Smith|  1000|    10|2016-12-01|\n",
      "|  7|Robert|  3000|    20|2023-06-25|\n",
      "| 12| Karan|  2200|    20|2018-06-16|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 15|  Neha|  1700|    20|2021-07-22|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 19|Monica|  2500|    20|2023-08-07|\n",
      "| 21| Sneha|  2700|    10|2022-12-14|\n",
      "| 22| David|  1000|    20|2017-02-17|\n",
      "| 24| Vinod|  1800|    10|2016-07-30|\n",
      "| 25| Meena|  2000|    20|2020-03-13|\n",
      "| 26| Harsh|  1600|    10|2021-09-25|\n",
      "| 28| Mohan|  1300|    10|2015-04-17|\n",
      "| 29| Priya|  1200|    20|2023-02-11|\n",
      "+---+------+------+------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# filter the data for depnto = 10 and depnto = 20 using in condition\n",
    "df = spark.read.csv(\"emp.csv\",header=True)\n",
    "df_filtered = df.filter((df.deptno.isin(10,20)))\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3fa68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+------+----------+\n",
      "|eno| ename|salary|deptno|       doj|\n",
      "+---+------+------+------+----------+\n",
      "| 10| Amber|  1000|    10|2018-05-14|\n",
      "|  2|  Amar|  1000|    10|2017-03-22|\n",
      "|  8| Sagar|  1000|    20|2020-11-30|\n",
      "|  4|Thomas|  1000|    10|2019-08-18|\n",
      "|  5|  Jade|  2000|    10|2021-02-10|\n",
      "|  6| Smith|  1000|    10|2016-12-01|\n",
      "|  7|Robert|  3000|    20|2023-06-25|\n",
      "|  3|  Nick|  1000|    30|2015-09-15|\n",
      "|  9| Naman|  4000|    30|2020-01-20|\n",
      "|  1| Vikas|  1000|    30|2017-10-03|\n",
      "| 11|Dennis| 41000|    30|2024-01-05|\n",
      "| 12| Karan|  2200|    20|2018-06-16|\n",
      "| 13|Simran|  1500|    10|2019-12-19|\n",
      "| 14|  Amit|  2000|    30|2022-04-09|\n",
      "| 15|  Neha|  1700|    20|2021-07-22|\n",
      "| 16| Rahul|  1200|    10|2016-03-28|\n",
      "| 17| Divya|  3000|    30|2015-11-11|\n",
      "| 18|Rakesh|  1800|    10|2020-09-04|\n",
      "| 19|Monica|  2500|    20|2023-08-07|\n",
      "| 20|  John|  2300|    30|2018-10-29|\n",
      "+---+------+------+------+----------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b0f93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ( Grouping data )\n",
    "df = spark.read.json(\"emp_details.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64a305d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|deptid|Total_salary|\n",
      "+------+------------+\n",
      "|    50|      156000|\n",
      "|    10|      272000|\n",
      "|    30|      237000|\n",
      "|    20|      227000|\n",
      "|    60|       66000|\n",
      "|    40|      195000|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the total salary per deptid\n",
    "df.groupBy('deptid').agg(F.sum(\"salary\").alias(\"Total_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04a68da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------------+\n",
      "|     city|deptid|Total_salary|\n",
      "+---------+------+------------+\n",
      "|  Chennai|    40|       65000|\n",
      "|   Mumbai|    20|       60000|\n",
      "|Bengaluru|    50|       48000|\n",
      "|     Pune|    20|       49000|\n",
      "|    Delhi|    20|       62000|\n",
      "|   Mumbai|    30|       59000|\n",
      "|Hyderabad|    50|       61000|\n",
      "|Ahmedabad|    30|       61000|\n",
      "|Bengaluru|    10|      110000|\n",
      "|  Kolkata|    10|      107000|\n",
      "|  Chennai|    60|       66000|\n",
      "|   Jaipur|    50|       47000|\n",
      "|     Pune|    30|       57000|\n",
      "|    Delhi|    40|      130000|\n",
      "|Hyderabad|    30|       60000|\n",
      "|    Surat|    20|       56000|\n",
      "|   Mumbai|    10|       55000|\n",
      "+---------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the total salary based on each deptid and city\n",
    "df.groupBy('city','deptid').agg(F.sum(\"salary\").alias(\"Total_salary\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00214e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+------------------+------------+---------------+\n",
      "|     city|min_salary|  max|        avg_salary|total_salary|total_employees|\n",
      "+---------+----------+-----+------------------+------------+---------------+\n",
      "|  Chennai|     65000|66000|           65500.0|      131000|              2|\n",
      "|   Mumbai|     55000|60000|           58000.0|      174000|              3|\n",
      "|Ahmedabad|     61000|61000|           61000.0|       61000|              1|\n",
      "|  Kolkata|     53000|54000|           53500.0|      107000|              2|\n",
      "|    Surat|     56000|56000|           56000.0|       56000|              1|\n",
      "|     Pune|     49000|57000|           53000.0|      106000|              2|\n",
      "|    Delhi|     62000|67000|           64000.0|      192000|              3|\n",
      "|Bengaluru|     48000|58000|52666.666666666664|      158000|              3|\n",
      "|Hyderabad|     60000|61000|           60500.0|      121000|              2|\n",
      "|   Jaipur|     47000|47000|           47000.0|       47000|              1|\n",
      "+---------+----------+-----+------------------+------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the min,max.avg,total salary from each city\n",
    "df_ans = df.groupBy('city').agg(F.min(\"salary\").alias(\"min_salary\"),F.max(\"salary\").alias(\"max\"),F.avg(\"salary\").alias(\"avg_salary\")\n",
    "                      ,F.sum(\"salary\").alias(\"total_salary\"),F.count(\"salary\").alias(\"total_employees\"))\n",
    "df_ans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b0862af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|deptid|total_count|\n",
      "+------+-----------+\n",
      "|    10|          3|\n",
      "|    20|          1|\n",
      "|    50|          2|\n",
      "+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter before gouping and order in ascending order of deptid\n",
    "\n",
    "df_filter = df.filter(df.salary <55000)\n",
    "#df_filter.show()\n",
    "df_grouped = df_filter.groupby('deptid').agg(F.count('eno').alias('total_count'))\n",
    "df_grouped.orderBy(df_grouped.deptid.asc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ed574d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|deptid|total_sal|\n",
      "+------+---------+\n",
      "|    10|   272000|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering the grouped data ( HAVING)\n",
    "# get me all the deptid where total_salary in the department is more than 250000\n",
    "\n",
    "# Way 1\n",
    "df_grouped = df.groupby('deptid').agg(F.sum('salary').alias('total_sal'))\n",
    "df_ans = df_grouped.filter(df_grouped.total_sal > 250000)\n",
    "df_ans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46814413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|deptid|total_sal|\n",
      "+------+---------+\n",
      "|    10|   272000|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Way 2 \n",
    "df_ans = df.groupby('deptid').agg(F.sum('salary').alias('total_sal')).filter('total_sal > 250000').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b116ad6b",
   "metadata": {},
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3afff6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---+------+\n",
      "|     city|deptid|eno|salary|\n",
      "+---------+------+---+------+\n",
      "|   Mumbai|    10|101| 55000|\n",
      "|    Delhi|    20|102| 62000|\n",
      "|Bengaluru|    10|103| 58000|\n",
      "|Hyderabad|    30|104| 60000|\n",
      "|     Pune|    20|105| 49000|\n",
      "|  Kolkata|    10|106| 53000|\n",
      "|  Chennai|    40|107| 65000|\n",
      "|Ahmedabad|    30|108| 61000|\n",
      "|   Jaipur|    50|109| 47000|\n",
      "|    Surat|    20|110| 56000|\n",
      "|   Mumbai|    30|111| 59000|\n",
      "|    Delhi|    40|112| 63000|\n",
      "|Bengaluru|    10|113| 52000|\n",
      "|Hyderabad|    50|114| 61000|\n",
      "|  Chennai|    60|115| 66000|\n",
      "|     Pune|    30|116| 57000|\n",
      "|  Kolkata|    10|117| 54000|\n",
      "|   Mumbai|    20|118| 60000|\n",
      "|    Delhi|    40|119| 67000|\n",
      "|Bengaluru|    50|120| 48000|\n",
      "+---------+------+---+------+\n",
      "\n",
      "+------+--------+\n",
      "|deptid|deptname|\n",
      "+------+--------+\n",
      "|    10| Finance|\n",
      "|    20|      HR|\n",
      "|    30|      IT|\n",
      "|   100|  Travel|\n",
      "+------+--------+\n",
      "\n",
      "+----------+------+\n",
      "|  deptname|deptno|\n",
      "+----------+------+\n",
      "|   Finance|    10|\n",
      "|        HR|    20|\n",
      "|        IT|    30|\n",
      "|Operations|    40|\n",
      "| Marketing|    50|\n",
      "|     Legal|    70|\n",
      "|     Admin|    80|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp = spark.read.json(\"emp_details.json\")\n",
    "df_dept = spark.read.json(\"dept.json\")\n",
    "df_department = spark.read.json(\"department.json\")\n",
    "\n",
    "df_emp.show()\n",
    "df_dept.show()\n",
    "df_department.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab1bfb",
   "metadata": {},
   "source": [
    "# Joins with the same columns name in both dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c41986de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+------+--------+\n",
      "|deptid|     city|eno|salary|deptname|\n",
      "+------+---------+---+------+--------+\n",
      "|    10|   Mumbai|101| 55000| Finance|\n",
      "|    20|    Delhi|102| 62000|      HR|\n",
      "|    10|Bengaluru|103| 58000| Finance|\n",
      "|    30|Hyderabad|104| 60000|      IT|\n",
      "|    20|     Pune|105| 49000|      HR|\n",
      "|    10|  Kolkata|106| 53000| Finance|\n",
      "|    30|Ahmedabad|108| 61000|      IT|\n",
      "|    20|    Surat|110| 56000|      HR|\n",
      "|    30|   Mumbai|111| 59000|      IT|\n",
      "|    10|Bengaluru|113| 52000| Finance|\n",
      "|    30|     Pune|116| 57000|      IT|\n",
      "|    10|  Kolkata|117| 54000| Finance|\n",
      "|    20|   Mumbai|118| 60000|      HR|\n",
      "+------+---------+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df_emp.join(df_dept,on='deptid',how='inner').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "10aa6086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+------+--------+\n",
      "|deptid|     city|eno|salary|deptname|\n",
      "+------+---------+---+------+--------+\n",
      "|    30|Hyderabad|104| 60000|      IT|\n",
      "|    30|Ahmedabad|108| 61000|      IT|\n",
      "|    30|   Mumbai|111| 59000|      IT|\n",
      "|    30|     Pune|116| 57000|      IT|\n",
      "|    20|    Delhi|102| 62000|      HR|\n",
      "|    20|     Pune|105| 49000|      HR|\n",
      "|    20|    Surat|110| 56000|      HR|\n",
      "|    20|   Mumbai|118| 60000|      HR|\n",
      "|    10|   Mumbai|101| 55000| Finance|\n",
      "|    10|Bengaluru|103| 58000| Finance|\n",
      "|    10|  Kolkata|106| 53000| Finance|\n",
      "|    10|Bengaluru|113| 52000| Finance|\n",
      "|    10|  Kolkata|117| 54000| Finance|\n",
      "|    40|  Chennai|107| 65000|    NULL|\n",
      "|    50|   Jaipur|109| 47000|    NULL|\n",
      "|    40|    Delhi|112| 63000|    NULL|\n",
      "|    50|Hyderabad|114| 61000|    NULL|\n",
      "|    60|  Chennai|115| 66000|    NULL|\n",
      "|    40|    Delhi|119| 67000|    NULL|\n",
      "|    50|Bengaluru|120| 48000|    NULL|\n",
      "+------+---------+---+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# left join\n",
    "df_ans = df_emp.join(df_dept,on='deptid',how='left')\n",
    "df_ans.orderBy(df_ans.deptname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99b5bab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----+------+--------+\n",
      "|deptid|     city| eno|salary|deptname|\n",
      "+------+---------+----+------+--------+\n",
      "|   100|     NULL|NULL|  NULL|  Travel|\n",
      "|    30|     Pune| 116| 57000|      IT|\n",
      "|    30|   Mumbai| 111| 59000|      IT|\n",
      "|    30|Ahmedabad| 108| 61000|      IT|\n",
      "|    30|Hyderabad| 104| 60000|      IT|\n",
      "|    20|   Mumbai| 118| 60000|      HR|\n",
      "|    20|    Surat| 110| 56000|      HR|\n",
      "|    20|     Pune| 105| 49000|      HR|\n",
      "|    20|    Delhi| 102| 62000|      HR|\n",
      "|    10|  Kolkata| 117| 54000| Finance|\n",
      "|    10|Bengaluru| 113| 52000| Finance|\n",
      "|    10|  Kolkata| 106| 53000| Finance|\n",
      "|    10|Bengaluru| 103| 58000| Finance|\n",
      "|    10|   Mumbai| 101| 55000| Finance|\n",
      "+------+---------+----+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Right join\n",
    "df_ans = df_emp.join(df_dept,on='deptid',how='right')\n",
    "df_ans.orderBy(df_ans.deptname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "808001fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----+------+--------+\n",
      "|deptid|     city| eno|salary|deptname|\n",
      "+------+---------+----+------+--------+\n",
      "|   100|     NULL|NULL|  NULL|  Travel|\n",
      "|    30|Hyderabad| 104| 60000|      IT|\n",
      "|    30|Ahmedabad| 108| 61000|      IT|\n",
      "|    30|   Mumbai| 111| 59000|      IT|\n",
      "|    30|     Pune| 116| 57000|      IT|\n",
      "|    20|    Delhi| 102| 62000|      HR|\n",
      "|    20|     Pune| 105| 49000|      HR|\n",
      "|    20|    Surat| 110| 56000|      HR|\n",
      "|    20|   Mumbai| 118| 60000|      HR|\n",
      "|    10|   Mumbai| 101| 55000| Finance|\n",
      "|    10|Bengaluru| 103| 58000| Finance|\n",
      "|    10|  Kolkata| 106| 53000| Finance|\n",
      "|    10|Bengaluru| 113| 52000| Finance|\n",
      "|    10|  Kolkata| 117| 54000| Finance|\n",
      "|    40|  Chennai| 107| 65000|    NULL|\n",
      "|    40|    Delhi| 112| 63000|    NULL|\n",
      "|    40|    Delhi| 119| 67000|    NULL|\n",
      "|    50|   Jaipur| 109| 47000|    NULL|\n",
      "|    50|Hyderabad| 114| 61000|    NULL|\n",
      "|    50|Bengaluru| 120| 48000|    NULL|\n",
      "+------+---------+----+------+--------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Full/outer join\n",
    "df_ans = df_emp.join(df_dept,on='deptid',how='full')\n",
    "df_ans.orderBy(df_ans.deptname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "730a7c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+------+\n",
      "|deptid|     city|eno|salary|\n",
      "+------+---------+---+------+\n",
      "|    10|   Mumbai|101| 55000|\n",
      "|    20|    Delhi|102| 62000|\n",
      "|    10|Bengaluru|103| 58000|\n",
      "|    30|Hyderabad|104| 60000|\n",
      "|    20|     Pune|105| 49000|\n",
      "|    10|  Kolkata|106| 53000|\n",
      "|    30|Ahmedabad|108| 61000|\n",
      "|    20|    Surat|110| 56000|\n",
      "|    30|   Mumbai|111| 59000|\n",
      "|    10|Bengaluru|113| 52000|\n",
      "|    30|     Pune|116| 57000|\n",
      "|    10|  Kolkata|117| 54000|\n",
      "|    20|   Mumbai|118| 60000|\n",
      "+------+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left semi join\n",
    "df_emp.join(df_dept,on='deptid',how='left_semi').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "539f22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+------+\n",
      "|deptid|     city|eno|salary|\n",
      "+------+---------+---+------+\n",
      "|    40|  Chennai|107| 65000|\n",
      "|    50|   Jaipur|109| 47000|\n",
      "|    40|    Delhi|112| 63000|\n",
      "|    50|Hyderabad|114| 61000|\n",
      "|    60|  Chennai|115| 66000|\n",
      "|    40|    Delhi|119| 67000|\n",
      "|    50|Bengaluru|120| 48000|\n",
      "+------+---------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Left anti join\n",
    "df_emp.join(df_dept,on='deptid',how='left_anti').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85483af6",
   "metadata": {},
   "source": [
    "# Joins when both data framews having different common column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42110643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---+------+----------+------+\n",
      "|     city|deptid|eno|salary|  deptname|deptno|\n",
      "+---------+------+---+------+----------+------+\n",
      "|   Mumbai|    10|101| 55000|   Finance|    10|\n",
      "|    Delhi|    20|102| 62000|        HR|    20|\n",
      "|Bengaluru|    10|103| 58000|   Finance|    10|\n",
      "|Hyderabad|    30|104| 60000|        IT|    30|\n",
      "|     Pune|    20|105| 49000|        HR|    20|\n",
      "|  Kolkata|    10|106| 53000|   Finance|    10|\n",
      "|  Chennai|    40|107| 65000|Operations|    40|\n",
      "|Ahmedabad|    30|108| 61000|        IT|    30|\n",
      "|   Jaipur|    50|109| 47000| Marketing|    50|\n",
      "|    Surat|    20|110| 56000|        HR|    20|\n",
      "|   Mumbai|    30|111| 59000|        IT|    30|\n",
      "|    Delhi|    40|112| 63000|Operations|    40|\n",
      "|Bengaluru|    10|113| 52000|   Finance|    10|\n",
      "|Hyderabad|    50|114| 61000| Marketing|    50|\n",
      "|     Pune|    30|116| 57000|        IT|    30|\n",
      "|  Kolkata|    10|117| 54000|   Finance|    10|\n",
      "|   Mumbai|    20|118| 60000|        HR|    20|\n",
      "|    Delhi|    40|119| 67000|Operations|    40|\n",
      "|Bengaluru|    50|120| 48000| Marketing|    50|\n",
      "+---------+------+---+------+----------+------+\n",
      "\n",
      "+---------+------+---+------+----------+------+\n",
      "|     city|deptid|eno|salary|  deptname|deptno|\n",
      "+---------+------+---+------+----------+------+\n",
      "|   Mumbai|    10|101| 55000|   Finance|    10|\n",
      "|    Delhi|    20|102| 62000|        HR|    20|\n",
      "|Bengaluru|    10|103| 58000|   Finance|    10|\n",
      "|Hyderabad|    30|104| 60000|        IT|    30|\n",
      "|     Pune|    20|105| 49000|        HR|    20|\n",
      "|  Kolkata|    10|106| 53000|   Finance|    10|\n",
      "|  Chennai|    40|107| 65000|Operations|    40|\n",
      "|Ahmedabad|    30|108| 61000|        IT|    30|\n",
      "|   Jaipur|    50|109| 47000| Marketing|    50|\n",
      "|    Surat|    20|110| 56000|        HR|    20|\n",
      "|   Mumbai|    30|111| 59000|        IT|    30|\n",
      "|    Delhi|    40|112| 63000|Operations|    40|\n",
      "|Bengaluru|    10|113| 52000|   Finance|    10|\n",
      "|Hyderabad|    50|114| 61000| Marketing|    50|\n",
      "|     Pune|    30|116| 57000|        IT|    30|\n",
      "|  Kolkata|    10|117| 54000|   Finance|    10|\n",
      "|   Mumbai|    20|118| 60000|        HR|    20|\n",
      "|    Delhi|    40|119| 67000|Operations|    40|\n",
      "|Bengaluru|    50|120| 48000| Marketing|    50|\n",
      "+---------+------+---+------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "df_emp.join(df_department,on=df_emp.deptid == df_department.deptno,how='inner').show()\n",
    "# or\n",
    "\n",
    "df_emp.join(df_department,df_emp.deptid == df_department.deptno,'inner').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e7e74",
   "metadata": {},
   "source": [
    "# complete for all other joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225aaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
